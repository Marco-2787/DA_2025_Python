{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff7772-2d76-4dbc-9460-2801f6b4c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_1 \n",
    "#Dal database AdventureWorks estraiamo la tabella dimproduct\n",
    "#Sulla colonna DealerPrice, utilizzando il metodo .round(), \n",
    "#arrotondiamo i valori alle due cifre decimali, \n",
    "#e poi al valore intero più vicino\n",
    "#Utilizzando il metodo .clip(), \n",
    "#facciamo in modo che i valori siano compresi tra un minimo di 0 e un massimo di 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d9a25c5-b925-4f21-a99d-e84b959e818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c18c34-ea18-4689-9841-24b49e20dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv(override=True, dotenv_path=\"C:/Users/Marco/Desktop/Epicode/Python/.env\")\n",
    "\n",
    "username = os.getenv(\"username\")\n",
    "password = os.getenv(\"password\")\n",
    "host = os.getenv(\"host\")\n",
    "dbname = os.getenv(\"dbname\")\n",
    "\n",
    "connection_string = \"mysql+pymysql://\" + username + \":\" + password + \"@\" + host + \"/\" + dbname\n",
    "\n",
    "db_engine = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "query = \"SELECT * FROM dimproduct\"\n",
    "DF=pd.read_sql(query, db_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310e170-e545-4555-915d-2dc4e54538c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"DealerPrice\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87569150-9e48-4353-9ea0-0807566a298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"DealerPrice\"].clip(lower=0, upper =1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e0bb1-36b6-4cdd-8210-7e837a428afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_2\n",
    "#Creiamo un DataFrame sintetico, \n",
    "#che contiene i guadagni mensili di diverse annate, con il seguente codice: \n",
    "#years = 5 \n",
    "#a = pd.DataFrame({\"Mese\": list(\"GFMAMGLASOND\"*years), \n",
    "#\"Anno\": np.repeat(list(range(years)), 12), \n",
    "#\"Guadagni\": np.random.randint(800, 5000, 12*years)}) \n",
    "#Calcola la somma cumulativa delle vendite per ogni mese utilizzando il metodo .cumsum() \n",
    "#Come sopra, ma raggruppato per ogni anno usando prima un .groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4aabb448-1ae7-408e-949c-79c439e1164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "years=5\n",
    "a = pd.DataFrame({\"Mese\": list(\"GFMAMGLASOND\"*years), \n",
    "                  \"Anno\": np.repeat(list(range(years)), 12), \n",
    "                  \"Guadagni\": np.random.randint(800, 5000, 12*years)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "51bd7ff2-a3f9-498d-95fc-73055d111185",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"VenditeCumulative\"]=a[\"Guadagni\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd34a6e-bee3-4b29-86fc-fb7053fc6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.groupby(\"Anno\")[\"Guadagni\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92407e3f-c9c9-4d2d-974b-a7be9fe74d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_3\n",
    "#Dal database AdventureWorks estraiamo la tabella dimcustomer\n",
    "#Trasformiamo i nomi dei clienti in modo che abbiano solo lettere minuscole, \n",
    "#e i cognomi in modo che abbiano solo lettere maiuscole \n",
    "#Sulla colonna EmailAddress, utilizzando il metodo .str.split(), \n",
    "#estraiamo nome utente e dominio \n",
    "#Sulla colonna Phone, estraiamo ogni parte del numero \n",
    "#(ad es. da \"1 (11) 500 555-0162\" a [\"1\", \"(11)\", \"500\", \"555-0162\"]) \n",
    "#Utilizzando il metodo .str.contains(), estraiamo tutti gli indirizzi e-mail che contengono il numero \"21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d8e521f-a716-4458-8cc6-e8338673d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_sql(\"SELECT * FROM dimcustomer\",db_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "46b52004-57a4-42b6-8e75-8b9753d4cd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1 (11) 500 555-0162\n",
       "1        1 (11) 500 555-0110\n",
       "2        1 (11) 500 555-0184\n",
       "3        1 (11) 500 555-0162\n",
       "4        1 (11) 500 555-0131\n",
       "                ...         \n",
       "18479    1 (11) 500 555-0136\n",
       "18480    1 (11) 500 555-0146\n",
       "18481    1 (11) 500 555-0144\n",
       "18482    1 (11) 500 555-0137\n",
       "18483    1 (11) 500 555-0141\n",
       "Name: Phone, Length: 18484, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Phone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c8245-9e9f-44c5-a8fe-045d405edab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.FirstName.str.lower()\n",
    "df.LastName.str.upper()\n",
    "df.EmailAddress.str.split(\"@\")\n",
    "df.Phone.str.split(\" \")\n",
    "df.loc[df.EmailAddress.str.contains(\"21\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a86bdb-dc00-4c9a-8957-bc88ac5ccf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_4\n",
    "#Estraiamo tutti gli indirizzi e-mail che contengono il numero \"20\" oppure il numero \"10\" \n",
    "#Calcolare la lunghezza di ogni indirizzo e-mail ed estrarre i dieci più lunghi e i dieci più corti \n",
    "#Modificare il dominio degli indirizzi e-mail da \"adventure-works.com\" a \"aw-db.com\" mediante il metodo .str.replace() \n",
    "#Dalla colonna AddressLine1 estraiamo tutti gli indirizzi che contengono la sottostringa \"Street\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0f033-44b0-46e5-858d-ef6eb0d73271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.EmailAddress.str.contains(\"20|10\")]\n",
    "df.EmailAddress.str.replace(\"adventure-works.com\",\"aw-db.com\")\n",
    "df.loc[df.AddressLine1.str.contains(\"Street\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fac009-c298-44ef-a0b4-a3f05dab5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.EmailAddress.sort_values()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037afcf-f803-4792-a039-590cf7e19957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.EmailAddress.sort_values()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8edb68e-c593-4820-9ce1-10f67e38a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EmailAddress'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a4a90-77c6-4f81-b838-d8b1cb40dc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[sorted(df.EmailAddress.str.len())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e51f6-436d-4ab1-b3e6-ab3a1871df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_5\n",
    "#Dai beginner_datasets carichiamo in un DataFrame il file facebook.csv, \n",
    "#che contiene dei post con data di pubblicazione, tipo (foto, video, …) e numero di reactions raccolte: \n",
    "#Con la funzione pd.to_datetime() convertiamo la colonna status_published in formato Timestamp \n",
    "#Utilizzando gli attributi .dt.year , .dt.month , .dt.day , .dt.dayofweek , .dt.dayofyear, \n",
    "#ottieniamo informazioni specifiche sulle date delle transazioni, come l'anno, \n",
    "#il mese, il giorno della settimana, il giorno dell'anno, eccetera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "88e649bd-1658-461e-bacc-c59817f0bd32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fb=pd.read_csv(\"C:/Users/Marco/Desktop/Epicode/Python/datasets/datasets/beginner_datasets/facebook.csv\", encoding=\"latin1\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "a2056ac5-670e-49aa-af70-a99830c0924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT=pd.to_datetime(fb[\"status_published\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72da86-9f41-48c5-8469-3a089dd52ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c05ed-f7a3-488c-b94b-ad9753a8c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc71ece-a59d-469a-a713-24a011d25944",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c9279-3a82-42ca-82a0-f2b194cdb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e00fcb-97b5-4ccd-b4c1-c52c4bc8cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de5116-c0fc-4263-af91-1e69d4e02af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_6\n",
    "#Estraiamo solo i post relativi al 2012 \n",
    "#Estraiamo solo i post relativi a maggio 2018 \n",
    "#Confrontiamo il numero di post pubblicati nei weekend \n",
    "#rispetto al numero di post pubblicati nel resto della settimana \n",
    "#Troviamo il primo e ultimo post pubblicati in ogni anno \n",
    "#Quanti tipi di post ci sono? E quanti per ogni tipo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894196d-b4d1-4b1a-836c-92db5ce413a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.loc[fb.status_published.str.contains(\"2012\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68486397-0579-4f08-814f-6ffb8633e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.loc[fb.status_published.str.contains(\"5/../2018\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311ef76-8c3a-45ff-be3c-5b2bc6cd3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_weekdays_flt = fb['status_published'].dt.dayofweek < 5\n",
    "post_weekend_flt = fb['status_published'].dt.dayofweek >= 5\n",
    "\n",
    "print('numero di post nel weekend: ', fb[ post_weekend_flt ].shape[0])\n",
    "print('numero di post negli altri giorni: ', fb[ post_weekdays_flt ].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf0ef7-97a6-46c2-a491-a0b1c4c9a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_anno = fb['status_published'].dt.year\n",
    "\n",
    "for anno in post_anno.unique():\n",
    "    fb_df_anno = fb.groupby(post_anno).get_group(anno).sort_values('status_published')\n",
    "    print(anno)\n",
    "    display('Primo post per ogni anno:', fb_df_anno.head(1))\n",
    "    display('Ultimo post per ogni anno:', fb_df_anno.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c95cd6-1509-4f97-b801-e1f510443927",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tipi di post:', fb['status_type'].unique(), '\\tnum:', fb['status_type'].nunique())\n",
    "print(fb.groupby('status_type').status_type.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e8641-b8b3-4c83-a4b2-f692a865bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_8\n",
    "#Dai beginner_dataset carichiamo in un DataFrame il file pokemon.csv:\n",
    "#Tramite i metodi .isnull() e .sum() controlliamo se ci sono valori nulli nel dataset \n",
    "#e contiamo quanti valori nulli ci sono in ogni colonna \n",
    "#Ci sono valori nulli? \n",
    "#Se sì, avrebbe senso cercare di riempirli?\n",
    "#Eliminiamo le righe che contengono valori nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5da555-37ad-4993-a4a7-2216b2bbcdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df = pd.read_csv(parent_folder + 'datasets/beginner_datasets/pokemon.csv')\n",
    "\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5b69b-879e-4768-ad49-60b50f5b3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a3ffe-9ca4-4c02-a68a-456573e392e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df[ pokemon_df[ 'Type 2' ].isnull() ][ 'Type 2' ].replace(np.nan, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bdbe5-f8a3-44fd-a797-ddca236db5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esercizio_9\n",
    "#Dai beginner_dataset carichiamo in un DataFrame il file automobile.csv:\n",
    "#Ci sono valori nulli? Dove? Quanti?\n",
    "#Quali righe hanno un valore nullo nella colonna num-of-doors?\n",
    "#Esaminando i dati nel dataset, cerchiamo una logica per sostituire i valori nulli nella colonna num-of-doors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "febc478d-eb5e-4aac-be36-dee39cc217ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=pd.read_csv(\"C:/Users/Marco/Desktop/Epicode/Python/datasets/datasets/beginner_datasets/automobile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1a5b5-7c34-42cb-b316-0cf7c4c70f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5d801-ebb6-49a2-8566-7b93b651ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.loc[cars[\"num-of-doors\"].isnull()]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bda95967-cc3c-48c1-93bd-f6dbcd1a38d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenendo conto che le marche di auto senza numero di porte sono dodge e mazda,probabilmente il valore null è frutto di un mancato inserimento dei dati. possiamo quindi sostituirlo con il valore minimo di porte -in questo caso 2- per non dover eliminare 2 righe di dati\n"
     ]
    }
   ],
   "source": [
    "print(\"tenendo conto che le marche di auto senza numero di porte sono dodge e mazda,probabilmente il valore null è frutto di un mancato inserimento dei dati. possiamo quindi sostituirlo con il valore minimo di porte -in questo caso 2- per non dover eliminare 2 righe di dati\")\n",
    "cars[\"num-of-doors\"]=cars[\"num-of-doors\"].replace(np.nan,\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "45816ab8-6d3a-4a0a-bd41-f9e9a9526135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_10\n",
    "#Abbiamo il seguente DataFrame che raccoglie le misurazioni di un sensore che misura la temperatura atmosferica giornaliera:\n",
    "\n",
    "#import numpy as np, pandas as pd\n",
    "#temp = pd.DataFrame({\"Giorno\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \n",
    "#\"Temperature\": [18, 19, 18, np.nan, 21, 20, 20, np.nan, 21, 23, np.nan, 23, 24]})\n",
    "#Il sensore a volte non funziona, dunque alcuni dati sono mancanti: \n",
    "#quale sarebbe la migliore strategia per gestirli?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e8a3f570-9cae-4135-a58a-355e5f4009eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({\"Giorno\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \"Temperature\": [18, 19, 18, np.nan, 21, 20, 20, np.nan, 21, 23, np.nan, 23, 24]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6534f794-3c74-4a7c-b285-3517c70c122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cosa migliore è fare un interpolate, mantenendo così il più possibile integro la qualità del dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     18.0\n",
       "1     19.0\n",
       "2     18.0\n",
       "3     19.5\n",
       "4     21.0\n",
       "5     20.0\n",
       "6     20.0\n",
       "7     20.5\n",
       "8     21.0\n",
       "9     23.0\n",
       "10    23.0\n",
       "11    23.0\n",
       "12    24.0\n",
       "Name: Temperature, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"la cosa migliore è fare un interpolate, mantenendo così il più possibile integro la qualità del dataframe\")\n",
    "temp[\"Temperature\"].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6fec2-39d6-41d1-978a-c54baa7ee21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_11\n",
    "#Nel pacchetto os della standard library c'è la funzione os.listdir() che permette di avere la lista dei nomi di file all'interno di una directory; \n",
    "#senza input di default li cerca nella directory di lavoro corrente, altrimenti si può passare un path per esaminare una directory specifica, \n",
    "#ad esempio os.listdir(\"mio_progetto/beginner_datasets/\")\n",
    "#Nella directory dei beginner_datasets, quali sono i dataset che contengono dati nulli?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5d88dba8-e6d6-42b0-8b5d-2181f0671219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: amazon.csv\t dati nulli: 0\n",
      "Dataset Name: anomaly.csv\t dati nulli: 0\n",
      "Dataset Name: asia_gdp.csv\t dati nulli: 0\n",
      "Dataset Name: automobile.csv\t dati nulli: 39\n",
      "Dataset Name: bank.csv\t dati nulli: 0\n",
      "Dataset Name: bike.csv\t dati nulli: 0\n",
      "Dataset Name: blood.csv\t dati nulli: 0\n",
      "Dataset Name: boston.csv\t dati nulli: 0\n",
      "Dataset Name: cancer.csv\t dati nulli: 0\n",
      "Dataset Name: concrete.csv\t dati nulli: 0\n",
      "Dataset Name: credit.csv\t dati nulli: 0\n",
      "Dataset Name: desktop.ini\t dati nulli: 0\n",
      "Dataset Name: diabetes.csv\t dati nulli: 0\n",
      "Dataset Name: diamond.csv\t dati nulli: 0\n",
      "Dataset Name: elections.csv\t dati nulli: 52\n",
      "Dataset Name: electrical_grid.csv\t dati nulli: 0\n",
      "Dataset Name: employee.csv\t dati nulli: 0\n",
      "Dataset Name: energy.csv\t dati nulli: 0\n",
      "Dataset Name: facebook.csv\t dati nulli: 0\n",
      "Dataset Name: forest.csv\t dati nulli: 0\n",
      "Dataset Name: france.csv\t dati nulli: 66\n",
      "Dataset Name: germany.csv\t dati nulli: 0\n",
      "Dataset Name: glass.csv\t dati nulli: 0\n",
      "Dataset Name: gold.csv\t dati nulli: 0\n",
      "Dataset Name: heart.csv\t dati nulli: 0\n",
      "Dataset Name: heart_disease.csv\t dati nulli: 0\n",
      "Dataset Name: hepatitis.csv\t dati nulli: 153\n",
      "Dataset Name: house.csv\t dati nulli: 7829\n",
      "Dataset Name: income.csv\t dati nulli: 4262\n",
      "Dataset Name: insurance.csv\t dati nulli: 0\n",
      "Dataset Name: ipl.csv\t dati nulli: 0\n",
      "Dataset Name: iris.csv\t dati nulli: 0\n",
      "Dataset Name: jewellery.csv\t dati nulli: 0\n",
      "Dataset Name: juice.csv\t dati nulli: 0\n",
      "Dataset Name: kiva.csv\t dati nulli: 0\n",
      "Dataset Name: mice.csv\t dati nulli: 1396\n",
      "Dataset Name: migration.csv\t dati nulli: 0\n",
      "Dataset Name: nba.csv\t dati nulli: 11\n",
      "Dataset Name: parkinsons.csv\t dati nulli: 0\n",
      "Dataset Name: pokemon.csv\t dati nulli: 386\n",
      "Dataset Name: poker.csv\t dati nulli: 0\n",
      "Dataset Name: population.csv\t dati nulli: 12\n",
      "Dataset Name: public_health.csv\t dati nulli: 0\n",
      "Dataset Name: pycaret_datasets.csv\t dati nulli: 0\n",
      "Dataset Name: questions.csv\t dati nulli: 0\n",
      "Dataset Name: satellite.csv\t dati nulli: 0\n",
      "Dataset Name: seeds.csv\t dati nulli: 4\n",
      "Dataset Name: spx.csv\t dati nulli: 0\n",
      "Dataset Name: traffic.csv\t dati nulli: 48143\n",
      "Dataset Name: tweets.csv\t dati nulli: 0\n",
      "Dataset Name: wholesale.csv\t dati nulli: 0\n",
      "Dataset Name: wikipedia.csv\t dati nulli: 68\n",
      "Dataset Name: wine.csv\t dati nulli: 0\n"
     ]
    }
   ],
   "source": [
    "DS_path=(\"C:/Users/Marco/Desktop/Epicode/Python/datasets/datasets/beginner_datasets/\")\n",
    "\n",
    "for dataset in os.listdir(DS_path):\n",
    "    df = pd.read_csv(DS_path + dataset)\n",
    "    print(f\"Dataset Name: {dataset}\\t\", \"dati nulli:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cde6e-41fa-4cb3-b236-94b93f380f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e8b27-1c85-4fbf-8036-55fd1af7ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esercizio_12\n",
    "#Dovremo usare un ciclo for per esaminare tutti i nomi dei file\n",
    "#Dovremo selezionare solo i nomi di file con estensione .csv (quindi usare un costrutto if)\n",
    "#Nel corpo dovremo leggere di volta in volta il file in esame, e caricarlo in un DataFrame con la funzione .read_csv()\n",
    "#Sul DataFrame dovremo utilizzare il metodo .isna() per trovare la maschera booleana dei dati nulli\n",
    "#Dovremo contare i dati nulli, utilizzando .sum(); potremmo doverlo utilizzare più di una volta\n",
    "#Dovremo stampare, o memorizzare in una list, solo i nomi dei file che contengono dati nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b86871a9-a731-46a0-8e90-21280a9d9d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: amazon.csv\t dati nulli: 0\n",
      "Dataset Name: anomaly.csv\t dati nulli: 0\n",
      "Dataset Name: asia_gdp.csv\t dati nulli: 0\n",
      "Dataset Name: automobile.csv\t dati nulli: 0\n",
      "Dataset Name: bank.csv\t dati nulli: 0\n",
      "Dataset Name: bike.csv\t dati nulli: 0\n",
      "Dataset Name: blood.csv\t dati nulli: 0\n",
      "Dataset Name: boston.csv\t dati nulli: 0\n",
      "Dataset Name: cancer.csv\t dati nulli: 0\n",
      "Dataset Name: concrete.csv\t dati nulli: 0\n",
      "Dataset Name: credit.csv\t dati nulli: 0\n",
      "Dataset Name: desktop.ini\t dati nulli: 0\n",
      "Dataset Name: diabetes.csv\t dati nulli: 0\n",
      "Dataset Name: diamond.csv\t dati nulli: 0\n",
      "Dataset Name: elections.csv\t dati nulli: 0\n",
      "Dataset Name: electrical_grid.csv\t dati nulli: 0\n",
      "Dataset Name: employee.csv\t dati nulli: 0\n",
      "Dataset Name: energy.csv\t dati nulli: 0\n",
      "Dataset Name: facebook.csv\t dati nulli: 0\n",
      "Dataset Name: forest.csv\t dati nulli: 0\n",
      "Dataset Name: france.csv\t dati nulli: 0\n",
      "Dataset Name: germany.csv\t dati nulli: 0\n",
      "Dataset Name: glass.csv\t dati nulli: 0\n",
      "Dataset Name: gold.csv\t dati nulli: 0\n",
      "Dataset Name: heart.csv\t dati nulli: 0\n",
      "Dataset Name: heart_disease.csv\t dati nulli: 0\n",
      "Dataset Name: hepatitis.csv\t dati nulli: 0\n",
      "Dataset Name: house.csv\t dati nulli: 0\n",
      "Dataset Name: income.csv\t dati nulli: 0\n",
      "Dataset Name: insurance.csv\t dati nulli: 0\n",
      "Dataset Name: ipl.csv\t dati nulli: 0\n",
      "Dataset Name: iris.csv\t dati nulli: 0\n",
      "Dataset Name: jewellery.csv\t dati nulli: 0\n",
      "Dataset Name: juice.csv\t dati nulli: 0\n",
      "Dataset Name: kiva.csv\t dati nulli: 0\n",
      "Dataset Name: mice.csv\t dati nulli: 0\n",
      "Dataset Name: migration.csv\t dati nulli: 0\n",
      "Dataset Name: nba.csv\t dati nulli: 0\n",
      "Dataset Name: parkinsons.csv\t dati nulli: 0\n",
      "Dataset Name: pokemon.csv\t dati nulli: 0\n",
      "Dataset Name: poker.csv\t dati nulli: 0\n",
      "Dataset Name: population.csv\t dati nulli: 0\n",
      "Dataset Name: public_health.csv\t dati nulli: 0\n",
      "Dataset Name: pycaret_datasets.csv\t dati nulli: 0\n",
      "Dataset Name: questions.csv\t dati nulli: 0\n",
      "Dataset Name: satellite.csv\t dati nulli: 0\n",
      "Dataset Name: seeds.csv\t dati nulli: 0\n",
      "Dataset Name: spx.csv\t dati nulli: 0\n",
      "Dataset Name: traffic.csv\t dati nulli: 0\n",
      "Dataset Name: tweets.csv\t dati nulli: 0\n",
      "Dataset Name: wholesale.csv\t dati nulli: 0\n",
      "Dataset Name: wikipedia.csv\t dati nulli: 0\n",
      "Dataset Name: wine.csv\t dati nulli: 0\n"
     ]
    }
   ],
   "source": [
    "DS_path=(\"C:/Users/Marco/Desktop/Epicode/Python/datasets/datasets/beginner_datasets/\")\n",
    "\n",
    "for dataset in os.listdir(DS_path):\n",
    "    if df.isnull().sum().sum()>0:\n",
    "       df = pd.read_csv(DS_path + dataset)\n",
    "    print(f\"Dataset Name: {dataset}\\t\", \"dati nulli:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e694eb7-9022-43c7-a73d-54e69da9db27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
